{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Word-in-Context Disambiguation (WiC)\n",
        "This notebook contains the code for the first homework of NLP course 2021 at Sapienza, University of Rome.\n",
        "<br>\n",
        "**Author**: Leonardo Emili (1802989)"
      ],
      "metadata": {
        "id": "yj7Nu_vOBjP_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup the environment"
      ],
      "metadata": {
        "id": "BVh7CH5cBmGH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "print(gpu_info)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri May  9 16:23:29 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6yNvMR4BoXi",
        "outputId": "53888ca3-d1a1-4eb0-9feb-c8bd06d60736"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "#@title General settings\n",
        "#@markdown ##### If using GDrive to copy files, make sure to name them correctly.\n",
        "copy_from_drive = True #@param {type:\"boolean\"}\n",
        "try:\n",
        "    # Setup the project directory if running on Colab\n",
        "    from google.colab import drive\n",
        "    !git clone https://github.com/SapienzaNLP/nlp2021-hw1\n",
        "    %cd nlp2021-hw1\n",
        "\n",
        "    if copy_from_drive:\n",
        "        drive.mount('/content/gdrive')\n",
        "        !cp ../gdrive/MyDrive/GoogleNews-vectors-negative300.txt data/\n",
        "    else:\n",
        "        # Download and extract pretrained 300d word2vec word embeddings (may take longer)\n",
        "        !pip install wget\n",
        "        !wget https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz -P data/\n",
        "        !gzip -d data/GoogleNews-vectors-negative300.bin.gz\n",
        "\n",
        "        # Download and extract pretrained GloVe embeddings\n",
        "        !wget http://nlp.stanford.edu/data/glove.6B.zip -P data/\n",
        "        !unzip data/glove.6B.zip -d data/\n",
        "except:\n",
        "    pass"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nlp2021-hw1'...\n",
            "remote: Enumerating objects: 40, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 40 (delta 11), reused 18 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (40/40), 1.01 MiB | 7.46 MiB/s, done.\n",
            "Resolving deltas: 100% (11/11), done.\n",
            "/content/nlp2021-hw1/nlp2021-hw1\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-W_2NVoA7T2",
        "outputId": "221cc819-2bfb-4ea8-e1c7-e4ab1edb99c0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import dependencies"
      ],
      "metadata": {
        "id": "2-CnwkqJBy6G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "from collections import namedtuple, defaultdict\n",
        "from tqdm import tqdm\n",
        "from typing import *\n",
        "import numpy as np\n",
        "import random as rnd\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "_ = nltk.download('wordnet')\n",
        "_ = nltk.download('punkt')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwtk9vUmBN0K",
        "outputId": "71397fd5-e36f-4b2a-8175-8bd0ccb9eca1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the dataset"
      ],
      "metadata": {
        "id": "CK2ZDYZVDa6O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "train_df = pd.read_json('data/train.jsonl', lines=True)\n",
        "train_df.label = train_df.label.apply(lambda v: v == 'True')\n",
        "train_df.drop(\"id\", axis=1, inplace=True)\n",
        "dev_df = pd.read_json('data/dev.jsonl', lines=True)\n",
        "dev_df.label = dev_df.label.apply(lambda v: v == 'True')\n",
        "dev_df.drop(\"id\", axis=1, inplace=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Xr4tYu2l9wSz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data insights"
      ],
      "metadata": {
        "id": "IgQyigM4Ddu_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "train_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    lemma   pos                                          sentence1  \\\n",
              "0    play  NOUN  In that context of coordination and integratio...   \n",
              "1    play  NOUN  In that context of coordination and integratio...   \n",
              "2  esteem  NOUN  We would also like to convey our esteem and co...   \n",
              "3  esteem  NOUN  We would also like to convey our esteem and co...   \n",
              "4  holder  NOUN  This growth is the direct result of the increa...   \n",
              "\n",
              "                                           sentence2  start1  end1  start2  \\\n",
              "0  A musical play on the same subject was also st...      69    73      10   \n",
              "1  In schools, when water is needed, it is girls ...      69    73     112   \n",
              "2  Father Lini said that, because of that, the Un...      33    39     106   \n",
              "3  This attests to the esteem and trust enjoyed b...      33    39      20   \n",
              "4  A person may be either the holder of an option...      74    81      27   \n",
              "\n",
              "   end2  label  \n",
              "0    14  False  \n",
              "1   116  False  \n",
              "2   112   True  \n",
              "3    26   True  \n",
              "4    33   True  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bee62f2c-ab70-45df-820a-0465f1deff48\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemma</th>\n",
              "      <th>pos</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>start1</th>\n",
              "      <th>end1</th>\n",
              "      <th>start2</th>\n",
              "      <th>end2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>play</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>In that context of coordination and integratio...</td>\n",
              "      <td>A musical play on the same subject was also st...</td>\n",
              "      <td>69</td>\n",
              "      <td>73</td>\n",
              "      <td>10</td>\n",
              "      <td>14</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>play</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>In that context of coordination and integratio...</td>\n",
              "      <td>In schools, when water is needed, it is girls ...</td>\n",
              "      <td>69</td>\n",
              "      <td>73</td>\n",
              "      <td>112</td>\n",
              "      <td>116</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>esteem</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>We would also like to convey our esteem and co...</td>\n",
              "      <td>Father Lini said that, because of that, the Un...</td>\n",
              "      <td>33</td>\n",
              "      <td>39</td>\n",
              "      <td>106</td>\n",
              "      <td>112</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>esteem</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>We would also like to convey our esteem and co...</td>\n",
              "      <td>This attests to the esteem and trust enjoyed b...</td>\n",
              "      <td>33</td>\n",
              "      <td>39</td>\n",
              "      <td>20</td>\n",
              "      <td>26</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>holder</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>This growth is the direct result of the increa...</td>\n",
              "      <td>A person may be either the holder of an option...</td>\n",
              "      <td>74</td>\n",
              "      <td>81</td>\n",
              "      <td>27</td>\n",
              "      <td>33</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bee62f2c-ab70-45df-820a-0465f1deff48')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bee62f2c-ab70-45df-820a-0465f1deff48 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bee62f2c-ab70-45df-820a-0465f1deff48');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c2c3efb7-b593-404a-a4e2-fe1e58784d1c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c2c3efb7-b593-404a-a4e2-fe1e58784d1c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c2c3efb7-b593-404a-a4e2-fe1e58784d1c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 8000,\n  \"fields\": [\n    {\n      \"column\": \"lemma\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3726,\n        \"samples\": [\n          \"mystical\",\n          \"umbrella\",\n          \"typical\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pos\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"ADJ\",\n          \"ADV\",\n          \"NOUN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3994,\n        \"samples\": [\n          \"By then the Democratic-dominated state legislatures had imposed racial segregation and were underfunding black schools and other facilities.\",\n          \"Indeed, billions of people today enjoy human rights and live in dignity, free from disease, ignorance and fear, enjoying the benefits of technology and scientific advances and able to take full advantage of the process of globalization.\",\n          \"Registration fees for the Congress and room and board expenses for participants from developing countries were also covered by the sponsors of the Workshop.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7991,\n        \"samples\": [\n          \"A rubbing of this was collected by David Crockett Graham and is in the Field Museum of Natural History.\",\n          \"Three river valleys punctuate the cliff face, making way for the harbours of F\\u00e9camp sheltering on the Valmont river, Dieppe on the Arques, and Tr\\u00e9port on the Bresle.\",\n          \"Care need to be taken to avoid epicormic shoots growing on trunks of surrounding trees such that they lead to knotty wood, if timber production is desired.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"start1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 47,\n        \"min\": 0,\n        \"max\": 381,\n        \"num_unique_values\": 227,\n        \"samples\": [\n          71,\n          2,\n          57\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 47,\n        \"min\": 3,\n        \"max\": 390,\n        \"num_unique_values\": 233,\n        \"samples\": [\n          150,\n          213,\n          240\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"start2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46,\n        \"min\": 0,\n        \"max\": 369,\n        \"num_unique_values\": 244,\n        \"samples\": [\n          144,\n          28,\n          57\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46,\n        \"min\": 3,\n        \"max\": 377,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          42,\n          35,\n          191\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "K3iRmIK_DhaA",
        "outputId": "934b2b9c-fb57-4091-8423-9e840ba87df8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2)\n",
        "figsize = (12,4)\n",
        "fig.suptitle(\"POS tags distribution (train vs dev set)\", fontsize=14)\n",
        "_ = train_df.pos.value_counts().plot(kind='bar', legend=True, ax=ax1, figsize=figsize)\n",
        "_ = dev_df.pos.value_counts().plot(kind='bar', legend=True, ax=ax2, figsize=figsize)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "-NcuNVrHDjOx",
        "outputId": "5c55623a-7759-40af-d6de-02552ce8014c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility functions"
      ],
      "metadata": {
        "id": "uCa4ytVJDq1c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "# Useful namedtuple to hold token's information\n",
        "Token = namedtuple('Token', 'text lemma pos')\n",
        "\n",
        "def set_seed(seed: int = 42) -> None:\n",
        "    ''' Manually set the reproducibility seed. '''\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    rnd.seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "def parse_sentence(row_sent: pd.Series) -> Tuple[List[Token], List[Token], float]:\n",
        "    '''\n",
        "    Returns the sentence pair (s1, s2) that contains a list of parsed tokens.\n",
        "    '''\n",
        "    lemma, pos, s1, s2, start1, end1, start2, end2, label = row_sent\n",
        "    target_word_1, target_word_2 = s1[start1:end1], s2[start2:end2]\n",
        "\n",
        "    def _parse_sentence(s: str) -> List[Token]:\n",
        "        ''' Returns the collection of tokens for a given sentence [s]. '''\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        return [Token(t, lemmatizer.lemmatize(t), None) for t in word_tokenize(s)]\n",
        "\n",
        "    s1_prefix, s1_suffix = _parse_sentence(s1[:start1]), _parse_sentence(s1[end1:])\n",
        "    parsed_s1 = s1_prefix \\\n",
        "                + [Token(target_word_1, lemma, pos)] \\\n",
        "                + s1_suffix\n",
        "\n",
        "    s2_prefix, s2_suffix = _parse_sentence(s2[:start2]), _parse_sentence(s2[end2:])\n",
        "    parsed_s2 = s2_prefix \\\n",
        "                + [Token(target_word_2, lemma, pos)] \\\n",
        "                + s2_suffix\n",
        "    return parsed_s1, parsed_s2, float(label)\n",
        "\n",
        "def parse_sentences(\n",
        "    df: pd.DataFrame,\n",
        "    tag: str,\n",
        "    vectorize_fn = None,\n",
        "    word2idx: Dict[str, int] = None\n",
        "    ) -> List[Tuple[List[Token]]]:\n",
        "    '''\n",
        "    Returns the collection of sentence pairs, where for each token in the sentence we have\n",
        "    the named tuple (text, lemma, pos), where pos is None iff that is the target token.\n",
        "    '''\n",
        "    parsed_sentences = []\n",
        "    _word2idx = word2idx.copy() # Override defaultdict default behaviour\n",
        "    for _, row in tqdm(df.iterrows(), leave=True, position=0, total=len(df), desc=f'Parsing {tag} split'):\n",
        "        s1, s2, label = parse_sentence(row)\n",
        "        if vectorize_fn is not None:\n",
        "            s1, s2 = vectorize_fn(s1, s2, _word2idx)\n",
        "        parsed_sentences.append((s1, s2, label))\n",
        "    return parsed_sentences\n",
        "\n",
        "def vectorize_sentence_pair(\n",
        "    s1: List[Token],\n",
        "    s2: List[Token],\n",
        "    word2idx: Dict[str, int]\n",
        "    ) -> Tuple[List[Token], List[Token]]:\n",
        "    ''' Simple vectorizer function that returns a list of indices for each input sentence. '''\n",
        "    return [word2idx[t.lemma] for t in s1], [word2idx[t.lemma] for t in s2]\n",
        "\n",
        "def collate_fn(\n",
        "    batch: List[Tuple[List[Token], List[Token], bool]],\n",
        "    padding_idx: int = 0\n",
        "    ) -> Tuple[Tuple[torch.Tensor, torch.Tensor], Tuple[torch.Tensor, torch.Tensor], torch.Tensor]:\n",
        "    ''' Collate function used to pad input sequences up to maximum local length. '''\n",
        "\n",
        "    sentence_pair_lengths = [(len(s1),len(s2)) for s1,s2,*_ in batch]\n",
        "    X1_lengths, X2_lengths = map(torch.tensor, zip(*sentence_pair_lengths))\n",
        "\n",
        "    X1, X2, Y = zip(*[(torch.tensor(s1),torch.tensor(s2),y) for s1,s2,y in batch])\n",
        "    X1 = pad_sequence(X1, batch_first=True, padding_value=padding_idx)\n",
        "    X2 = pad_sequence(X2, batch_first=True, padding_value=padding_idx)\n",
        "\n",
        "    return (X1, X2), (X1_lengths, X2_lengths), torch.tensor(Y)\n",
        "\n",
        "def move_to_device(device: str, *args: Tuple[torch.Tensor]) -> Tuple[torch.Tensor]:\n",
        "    ''' Moves a collections of tensors to the specified device if they are not already there. '''\n",
        "    return tuple(arg.to(device) if str(arg.device) != device else arg for arg in args)\n",
        "\n",
        "def plot_logs(logs: Dict[str, List[float]]) -> None:\n",
        "    ''' Utility function to plot loss/accuracy curves over epochs. '''\n",
        "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18,8))\n",
        "    bins = list(range(len(logs['train_history'])))\n",
        "    ax1.plot(bins, logs['train_history'], label='Train loss')\n",
        "    ax1.plot(bins, logs['valid_history'], label='Test loss')\n",
        "    ax2.plot(bins, logs['train_accuracy'], label='Train accuracy')\n",
        "    ax2.plot(bins, logs['valid_accuracy'], label='Test accuracy')\n",
        "    ax1.set_title(\"Train/dev loss\", fontsize=14)\n",
        "    ax2.set_title(\"Train/dev accuracy\", fontsize=14)\n",
        "    ax1.set_ylabel('Loss', fontsize=12)\n",
        "    ax2.set_ylabel('Accuracy', fontsize=12)\n",
        "    ax1.set_xlabel('Epochs', fontsize=12)\n",
        "    ax2.set_xlabel('Epochs', fontsize=12)\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax2.legend(loc=\"upper left\")\n",
        "    plt.show()\n",
        "\n",
        "def save_vocab(vocab: DefaultDict, path: str = 'model/vocab.pkl') -> None:\n",
        "    ''' Utility function used to persist out the input vocabulary. '''\n",
        "    with open(path, 'wb') as f:\n",
        "        pickle.dump(dict(vocab), f)\n",
        "\n",
        "def make_averager(precision: int = 12) -> Callable[[Optional[float], Optional[float]], float]:\n",
        "    \"\"\" Returns a function that maintains a running average\n",
        "\n",
        "    :returns: running average function\n",
        "    This utility function is mainly an adaptation from https://github.com/erodola/DLAI-s2-2021\n",
        "    \"\"\"\n",
        "    count = 0\n",
        "    total = 0\n",
        "    precision = precision\n",
        "\n",
        "    def averager(new_value: Optional[float]=None, count_update: Optional[float]=None) -> float:\n",
        "        \"\"\" Running averager\n",
        "\n",
        "        :param new_value: number to add to the running average,\n",
        "                          if None returns the current average\n",
        "        :returns: the current average\n",
        "        \"\"\"\n",
        "        nonlocal count, total\n",
        "        if new_value is None:\n",
        "            return round(total / count, precision) if count else float(\"nan\")\n",
        "        count += count_update if count_update is not None else 1\n",
        "        total += new_value\n",
        "        return round(total / count, precision)\n",
        "\n",
        "    return averager\n",
        "\n",
        "def better_params_found(val_history: List[float], minimize: bool = True) -> bool:\n",
        "    ''' Returns the decision based on model's accuracy iff minimize is true. '''\n",
        "    if minimize:\n",
        "        return True if len(val_history) <= 1 else val_history[-1] < min(val_history[:-1])\n",
        "    return True if len(val_history) <= 1 else val_history[-1] > max(val_history[:-1])\n",
        "\n",
        "def get_device(model: nn.Module) -> str:\n",
        "    ''' Utility function used to determine the device the input model is running on. '''\n",
        "    return 'cuda:0' if next(model.parameters()).is_cuda else 'cpu'\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(\n",
        "    model: nn.Module,\n",
        "    dataloader: DataLoader,\n",
        "    loss_fn: Callable[[torch.Tensor, torch.Tensor], float],\n",
        "    loss_avg: Callable[[Optional[float], Optional[float]], float],\n",
        "    accuracy_avg: Callable[[Optional[float], Optional[float]], float]\n",
        "    ) -> List[float]:\n",
        "    ''' Evaluation routine that returns the list of model predictions. '''\n",
        "    predictions = []\n",
        "    for (x1, x2), (x1_lengths, x2_lengths), y in dataloader:\n",
        "        x1, x2, y = move_to_device(get_device(model), x1, x2, y)\n",
        "        y_hat = model(x1, x2, x1_lengths, x2_lengths)\n",
        "\n",
        "        # Update dev loss/accuracy\n",
        "        loss = loss_fn(y_hat, y.float())\n",
        "        loss_avg(loss.item())\n",
        "        predictions += y_hat.round().tolist()\n",
        "        correct_predictions = (y_hat.round() == y).sum().item()\n",
        "        accuracy_avg(correct_predictions, count_update=y_hat.shape[0])\n",
        "    return predictions\n",
        "\n",
        "def load_vocab(path: str = 'model/vocab.pkl', unk_index: int = 1) -> defaultdict:\n",
        "    ''' Utility function to load a vocabulary from path. '''\n",
        "    with open(path, 'rb') as f:\n",
        "         vocab = defaultdict(lambda: unk_index, pickle.load(f))\n",
        "    return vocab\n",
        "\n",
        "def vocab_from_df(df: pd.DataFrame, min_frequency: int = 1) -> List[str]:\n",
        "    '''\n",
        "    Returns the vocabulary derived the input DataFrame object (e.g. the train split).\n",
        "    It additionally filters out words that occur less than min_frequency times.\n",
        "    '''\n",
        "    counter = Counter()\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    counter.update([lemmatizer.lemmatize(word) for sentence in df.sentence1 for word in word_tokenize(sentence)])\n",
        "    counter.update([lemmatizer.lemmatize(word) for sentence in df.sentence2 for word in word_tokenize(sentence)])\n",
        "    vocab = set([k for k,v in counter.items() if v >= min_frequency])\n",
        "    return vocab"
      ],
      "outputs": [],
      "metadata": {
        "id": "jbf_ens0CJiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load pretrained word embeddings"
      ],
      "metadata": {
        "id": "s91JCQfYExVc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "def decode_word2vec_binaries(path: str) -> None:\n",
        "    ''' Utility function used to decode Word2Vec embeddings from .bin file. '''\n",
        "    if not os.path.exists(f'{path}.txt'):\n",
        "        from gensim.models.keyedvectors import KeyedVectors\n",
        "        # Import KeyedVectors to extract the word2vec data structure and save it into .txt file\n",
        "        word2vec = KeyedVectors.load_word2vec_format(f'{path}.bin', binary=True)\n",
        "        word2vec.save_word2vec_format(f'{path}.txt', binary=False)\n",
        "        del word2vec    # Free it from memory and build the vocab by ourselves for the sake of the hw\n",
        "\n",
        "def load_pretrained_embeddings(\n",
        "    vocab: Set,\n",
        "    path: str = 'data/GoogleNews-vectors-negative300',\n",
        "    words_limit: int = 1_000_000,\n",
        "    tag: str = 'Word2Vec',\n",
        "    delim: str = ' ',\n",
        "    pad_index: int = 0,\n",
        "    unk_index: int = 1\n",
        "    ) -> Tuple[Dict[str, int], torch.Tensor]:\n",
        "    ''' Loads pretrained embeddings from file and maps vocabulary words to vectors. '''\n",
        "\n",
        "    # Special tokens should have unique indexes\n",
        "    assert pad_index != unk_index\n",
        "    if tag == 'Word2Vec':\n",
        "        # Word2Vec are originally stored as binary file, parse it into plain file to be used later\n",
        "        decode_word2vec_binaries(path)\n",
        "\n",
        "    # Define the mapping to vectorize sentences and the embedding tensor\n",
        "    word2idx = {'<PAD>': pad_index, '<UNK>': unk_index}\n",
        "    vectors_store = []\n",
        "\n",
        "    with open(f'{path}.txt', 'r') as f:\n",
        "        if tag == 'Word2Vec':\n",
        "            n, embedding_size = map(int, next(f).split())\n",
        "        elif tag == 'GloVe':\n",
        "            n, embedding_size = (None, 300)\n",
        "        else:\n",
        "            raise Exception('Supported embeddings are Word2Vec and GloVe.')\n",
        "\n",
        "        # Initialize three vectors: respectively for <PAD> and <UNK> tokens\n",
        "        vectors_store.append(torch.zeros(embedding_size))\n",
        "        vectors_store.append(torch.zeros(embedding_size))\n",
        "\n",
        "        progress = tqdm(f, leave=True, position=0, total=n, desc=f'Loading pretrained {tag} embeddings')\n",
        "        for i, line in enumerate(progress):\n",
        "            # Read up to words_limit elements (special tokens excluded)\n",
        "            if len(word2idx) >= words_limit + 2: break\n",
        "            word, *embedding = line.split(delim)\n",
        "            # It is important to only use words that are present in the training set\n",
        "            if word not in vocab: continue\n",
        "            embedding = torch.tensor([float(c) for c in embedding])\n",
        "            word2idx[word] = len(vectors_store)\n",
        "            vectors_store.append(embedding)\n",
        "\n",
        "    # word2idx defines the encoding of each word in the vocabulary, otherwise encode it using the <UNK> special token\n",
        "    word2idx = defaultdict(lambda: unk_index, word2idx)\n",
        "    vectors_store = torch.stack(vectors_store)\n",
        "    return word2idx, vectors_store"
      ],
      "outputs": [],
      "metadata": {
        "id": "RtLVpBCoEzV8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the training and evaluation routines"
      ],
      "metadata": {
        "id": "_HPOMI_U3AuU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "def fit_evaluate(\n",
        "    model: nn.Module,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    train_dataloader: DataLoader,\n",
        "    dev_dataloader: DataLoader,\n",
        "    test_dataloader: DataLoader,\n",
        "    loss_fn: Callable[[torch.Tensor, torch.Tensor], float],\n",
        "    epochs: int = 50,\n",
        "    store_best_params_path: int = None,\n",
        "    display_precision: int = 4,\n",
        "    early_stopping_patience: int = -1\n",
        "    ) -> Dict[str, List[float]]:\n",
        "    '''\n",
        "    Fits the model on train data and validates it on the development set.\n",
        "    '''\n",
        "\n",
        "    # Initialize train/dev history\n",
        "    train_history = []\n",
        "    dev_history = []\n",
        "    train_accuracy = []\n",
        "    dev_accuracy = []\n",
        "\n",
        "    # Initialize the patience counter\n",
        "    patience_counter = 0\n",
        "\n",
        "    # Store best model's parameters\n",
        "    best_models_params = {\n",
        "        'epoch': 0,\n",
        "        'model_state_dict': {},\n",
        "        'optimizer_state_dict': {},\n",
        "        'loss': 0,\n",
        "    }\n",
        "\n",
        "    # Set up a simple progress bar and tqdm description\n",
        "    progress = tqdm(range(epochs), leave=True, position=0)\n",
        "    description = \"Epoch: 0, train_loss: 0, val_loss: 0, train_accuracy: 0, dev_accuracy: 0\"\n",
        "    if early_stopping_patience > 0: description += \", patience_counter: 0\"\n",
        "    progress.set_description(description)\n",
        "\n",
        "    for epoch in progress:\n",
        "        # Set the model in training mode\n",
        "        model.train()\n",
        "\n",
        "        # Initialize averagers for train set\n",
        "        train_loss_avg = make_averager(precision=display_precision)\n",
        "        train_accuracy_avg = make_averager(precision=display_precision)\n",
        "\n",
        "        for (x1, x2), (x1_lengths, x2_lengths), y in train_dataloader:\n",
        "            # Zero the gradients to prevent Pytorch from accumulating the gradients\n",
        "            optimizer.zero_grad()\n",
        "            x1, x2, y = move_to_device(get_device(model), x1, x2, y)\n",
        "            y_hat = model(x1, x2, x1_lengths, x2_lengths)\n",
        "\n",
        "            # Compute the loss and update the averagers\n",
        "            loss = loss_fn(y_hat, y.float())\n",
        "            train_loss_avg(loss.item())\n",
        "            correct_predictions = (y_hat.round() == y).sum().item()\n",
        "            train_accuracy_avg(correct_predictions, count_update=y_hat.shape[0])\n",
        "\n",
        "            # Compute the gradient of the loss and update model parameters\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Update train history\n",
        "        train_history.append(train_loss_avg())\n",
        "        train_accuracy.append(train_accuracy_avg())\n",
        "\n",
        "        # Initialize averagers for dev set\n",
        "        dev_loss_avg = make_averager(precision=display_precision)\n",
        "        dev_accuracy_avg = make_averager(precision=display_precision)\n",
        "\n",
        "        # Set the model in evaluation mode\n",
        "        model.eval()\n",
        "        evaluate(model, dev_dataloader, loss_fn, dev_loss_avg, dev_accuracy_avg)\n",
        "\n",
        "        # Update dev history\n",
        "        dev_history.append(dev_loss_avg())\n",
        "        dev_accuracy.append(dev_accuracy_avg())\n",
        "\n",
        "        # Check if we have a better value for the accuracy/loss function\n",
        "        if better_params_found(dev_accuracy, minimize=False):\n",
        "            best_models_params = {\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': dev_loss_avg()\n",
        "                }\n",
        "            # Save the current model parameters\n",
        "            torch.save(best_models_params, store_best_params_path)\n",
        "\n",
        "        # If early stopping is required and we observe an increase in the dev loss\n",
        "        if early_stopping_patience > 0 and (epoch > 0 and dev_history[-1] > dev_history[-2]):\n",
        "            if patience_counter >= early_stopping_patience:\n",
        "                # Patience treshold reached\n",
        "                break\n",
        "            patience_counter += 1\n",
        "\n",
        "\n",
        "        description = f\"Epoch: {epoch+1}, \" \\\n",
        "                + f\"train_loss: {train_loss_avg()}, \" \\\n",
        "                + f\"val_loss: {dev_loss_avg()}, \" \\\n",
        "                + f\"train_accuracy: {train_accuracy_avg()}, \" \\\n",
        "                + f\"dev_accuracy: {dev_accuracy_avg()}\"\n",
        "        if early_stopping_patience > 0:\n",
        "            description = description + f\", patience_counter: {patience_counter}\"\n",
        "        progress.set_description(description)\n",
        "\n",
        "    # Initialize averagers for dev set\n",
        "    test_loss_avg = make_averager(precision=display_precision)\n",
        "    test_accuracy_avg = make_averager(precision=display_precision)\n",
        "\n",
        "    # Set the model in evaluation mode and load the best model params\n",
        "    model.load_state_dict(best_models_params['model_state_dict'])\n",
        "    model.eval()    # Set the model in eval mode\n",
        "    evaluate(model, test_dataloader, loss_fn, test_loss_avg, test_accuracy_avg)\n",
        "    print(f\"Test_loss: {test_loss_avg()}, test_accuracy {test_accuracy_avg()}\")\n",
        "\n",
        "    best_model_idx = np.asarray(dev_accuracy).argmax()\n",
        "    print(f\"Best_model_index epoch: {best_model_idx}, valid_history_loss: {dev_history[best_model_idx]}, train_history loss: {train_history[best_model_idx]}, valid_history_accuracy: {max(dev_accuracy)}\")\n",
        "\n",
        "    train_logs = {\n",
        "        'train_history': train_history,\n",
        "        'valid_history': dev_history,\n",
        "        'train_accuracy': train_accuracy,\n",
        "        'valid_accuracy': dev_accuracy\n",
        "    }\n",
        "    return train_logs"
      ],
      "outputs": [],
      "metadata": {
        "id": "BUWWWPtp3HtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "q9YmnWndEfHM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M9Y8FjMo21iu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLt6RBqF23Be",
        "outputId": "67da3e8f-5d21-4a2a-8059-e9d22a4ba6d2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "class WiCDataset(Dataset):\n",
        "    ''' A small Dataset class that is responsible for holding data in the form of (sentence1, sentence2, label). '''\n",
        "    def __init__(self, df: pd.DataFrame, tag: str, vectorize_fn, word2idx: Dict[str, int]) -> None:\n",
        "        self.sents = parse_sentences(df, tag, vectorize_fn=vectorize_fn, word2idx=word2idx)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.sents)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
        "        return self.sents[idx]\n",
        "\n",
        "# Set reproducibility seed and the device to use\n",
        "set_seed()\n",
        "device = 'cuda:0'\n",
        "\n",
        "# Create vocabulary from train split and load pretrained embeddings\n",
        "vocabulary = vocab_from_df(train_df, min_frequency=2)\n",
        "word2idx, vectors_store = load_pretrained_embeddings(vocabulary)\n",
        "\n",
        "# Since we don't have a test set, randomly sample a small number of elements from the train\n",
        "# split to be able to understand the actual generalization capabilities of our models.\n",
        "test_set_size = 64\n",
        "test_df = pd.concat([\n",
        "    train_df[train_df.label == True].sample(test_set_size//2),\n",
        "    train_df[train_df.label == False].sample(test_set_size//2)\n",
        "])\n",
        "\n",
        "# Create train/dev/test datasets\n",
        "train_ds = WiCDataset(train_df.drop(index=test_df.index), 'train', vectorize_sentence_pair, word2idx)\n",
        "dev_ds = WiCDataset(dev_df, 'dev', vectorize_sentence_pair, word2idx)\n",
        "test_ds = WiCDataset(test_df, 'test', vectorize_sentence_pair, word2idx)\n",
        "\n",
        "# Create train/dev/test dataloaders\n",
        "batch_size = 128\n",
        "train_dataloader = DataLoader(train_ds, batch_size=batch_size, collate_fn=collate_fn, drop_last=True)\n",
        "dev_dataloader = DataLoader(dev_ds, batch_size=batch_size, collate_fn=collate_fn, drop_last=True)\n",
        "test_dataloader = DataLoader(test_ds, batch_size=batch_size, collate_fn=collate_fn, drop_last=False)\n",
        "\n",
        "# Save the vocabulary to use it in testing\n",
        "save_vocab(word2idx)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'gensim'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-e399cffbf59d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Create vocabulary from train split and load pretrained embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab_from_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_frequency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mword2idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectors_store\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_pretrained_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Since we don't have a test set, randomly sample a small number of elements from the train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-9165eaa5da7f>\u001b[0m in \u001b[0;36mload_pretrained_embeddings\u001b[0;34m(vocab, path, words_limit, tag, delim, pad_index, unk_index)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Word2Vec'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Word2Vec are originally stored as binary file, parse it into plain file to be used later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mdecode_word2vec_binaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Define the mapping to vectorize sentences and the embedding tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-9165eaa5da7f>\u001b[0m in \u001b[0;36mdecode_word2vec_binaries\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m''' Utility function used to decode Word2Vec embeddings from .bin file. '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{path}.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyedvectors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;31m# Import KeyedVectors to extract the word2vec data structure and save it into .txt file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mword2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{path}.bin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "f51gbC8oBbVA",
        "outputId": "59eb6510-0977-4565-a9da-55ff1b98696e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model definition"
      ],
      "metadata": {
        "id": "kgMwLb7KEgxs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class WiCMLP(nn.Module):\n",
        "    ''' A simple MLP neural network for the WiC task. '''\n",
        "    def __init__(\n",
        "        self,\n",
        "        vectors_store: torch.Tensor,\n",
        "        hidden_size: int\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        set_seed()  # Set the reproducibility seed\n",
        "        self.embedding = nn.Embedding.from_pretrained(vectors_store)\n",
        "        self.embedding_size = vectors_store.size(1)\n",
        "        self.fc1 = nn.Linear(2 * self.embedding_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        X1: torch.Tensor,\n",
        "        X2: torch.Tensor,\n",
        "        X1_lengths: torch.Tensor,\n",
        "        X2_lengths: torch.Tensor\n",
        "    ) -> torch.Tensor:\n",
        "        # Retrieve token word embeddings\n",
        "        X1 = self.embedding(X1)\n",
        "        X2 = self.embedding(X2)\n",
        "\n",
        "        # Aggregate sentence word embeddings ignoring the padding elements\n",
        "        X1 = torch.stack([x[:length].mean(dim=0) for x,length in zip(X1, X1_lengths)])\n",
        "        X2 = torch.stack([x[:length].mean(dim=0) for x,length in zip(X2, X2_lengths)])\n",
        "\n",
        "        # Concatenate the obtained representations\n",
        "        X = torch.cat((X1, X2), dim=-1)\n",
        "\n",
        "        # Pass it through two fully connected layers\n",
        "        X = torch.relu(self.fc1(X))\n",
        "        X = torch.sigmoid(self.fc2(X).squeeze(1))\n",
        "        return X\n",
        "\n",
        "class WiCLSTM(nn.Module):\n",
        "    ''' A simple BiLSTM neural network for the WiC task. '''\n",
        "    def __init__(\n",
        "        self,\n",
        "        vectors_store: torch.Tensor,\n",
        "        hidden_size: int,\n",
        "        batch_size: int,\n",
        "        bidirectional: bool = True\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        set_seed()  # Set the reproducibility seed\n",
        "        self.embedding = nn.Embedding.from_pretrained(vectors_store, freeze=True)\n",
        "        self.embedding_size = vectors_store.size(1)\n",
        "        self.batch_size = batch_size\n",
        "        self.lstm = nn.LSTM(self.embedding_size, hidden_size, batch_first=True, bidirectional=bidirectional)\n",
        "        self.dropout = nn.Dropout(0.65)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm_size = 2 * hidden_size if bidirectional else hidden_size\n",
        "        self.fc1 = nn.Linear(2 * self.lstm_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        X1: torch.Tensor,\n",
        "        X2: torch.Tensor,\n",
        "        X1_lengths: torch.Tensor,\n",
        "        X2_lengths: torch.Tensor\n",
        "    ) -> torch.Tensor:\n",
        "        # Retrieve token word embeddings\n",
        "        X1 = self.embedding(X1)\n",
        "        X2 = self.embedding(X2)\n",
        "\n",
        "        # Apply some dropout\n",
        "        X1 = self.dropout(X1)\n",
        "        X2 = self.dropout(X2)\n",
        "\n",
        "        # Pass the sentences through the LSTM layer\n",
        "        X1, _ = self.lstm(X1)\n",
        "        X2, _ = self.lstm(X2)\n",
        "\n",
        "        # Apply some dropout\n",
        "        X1 = self.dropout(X1)\n",
        "        X2 = self.dropout(X2)\n",
        "\n",
        "        # Aggregate sentence word embeddings ignoring the padding (mean)\n",
        "        X1 = torch.stack([x[:length].mean(dim=0) for x,length in zip(X1, X1_lengths)])\n",
        "        X2 = torch.stack([x[:length].mean(dim=0) for x,length in zip(X2, X2_lengths)])\n",
        "\n",
        "        # Concatenate the obtained representations\n",
        "        X = torch.cat((X1, X2), dim=-1)\n",
        "\n",
        "        # Pass it through two fully connected layers\n",
        "        X = torch.relu(self.dropout(self.fc1(X)))\n",
        "        X = torch.sigmoid(self.dropout(self.fc2(X)).squeeze(1))\n",
        "\n",
        "        return X"
      ],
      "outputs": [],
      "metadata": {
        "id": "DkOWVuiPCr35"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and hyperparameter tuning"
      ],
      "metadata": {
        "id": "aLkRRufe3PDK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Use binary cross entropy as loss function\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "# Define the list of hyperparameters\n",
        "hparams = {\n",
        "    'mlp': {\n",
        "        'lr': 0.015,\n",
        "        'momentum': 0.94,\n",
        "        'weight_decay': 1e-3\n",
        "    },\n",
        "    'mlp_epochs': 400,\n",
        "    'mlp_hidden_size': 256,\n",
        "\n",
        "    'lstm': {\n",
        "        'lr': 0.06,\n",
        "        'momentum': 0.92,\n",
        "    },\n",
        "    'lstm_epochs': 1000,\n",
        "    'lstm_hidden_size': 256\n",
        "}"
      ],
      "outputs": [],
      "metadata": {
        "id": "dZH_bPdwAW2U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First approach (simple MLP)"
      ],
      "metadata": {
        "id": "LgWUhlrD5P7J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Create an istance of the model to use\n",
        "mlp = WiCMLP(vectors_store, hparams['mlp_hidden_size']).to(device)\n",
        "\n",
        "# Define the optimizer to use\n",
        "mlp_optimizer = torch.optim.SGD(\n",
        "    mlp.parameters(),\n",
        "    **hparams['mlp']\n",
        ")\n",
        "\n",
        "# Fit the model on the train data and evaluate on the dev split\n",
        "train_logs = fit_evaluate(\n",
        "    mlp,\n",
        "    mlp_optimizer,\n",
        "    train_dataloader,\n",
        "    dev_dataloader,\n",
        "    test_dataloader,\n",
        "    loss_fn,\n",
        "    hparams['mlp_epochs'],\n",
        "    store_best_params_path = \"model/mlp.pt\"\n",
        ")\n",
        "\n",
        "# Show how the loss and the accuracy change over time\n",
        "plot_logs(train_logs)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Gcrtx85C5Rfl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Second approach (using LSTM layer)"
      ],
      "metadata": {
        "id": "Rxq4xtKx53rq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Create an istance of the model to use\n",
        "lstm = WiCLSTM(vectors_store, hparams['lstm_hidden_size'], batch_size).to(device)\n",
        "\n",
        "# Define the optimizer to use\n",
        "lstm_optimizer = torch.optim.SGD(\n",
        "    lstm.parameters(),\n",
        "    **hparams['lstm']\n",
        ")\n",
        "\n",
        "# Fit the model on the train data and evaluate on the dev split\n",
        "train_logs = fit_evaluate(\n",
        "    lstm,\n",
        "    lstm_optimizer,\n",
        "    train_dataloader,\n",
        "    dev_dataloader,\n",
        "    test_dataloader,\n",
        "    loss_fn,\n",
        "    hparams['lstm_epochs'],\n",
        "    store_best_params_path = \"model/lstm.pt\"\n",
        ")\n",
        "\n",
        "# Show how the loss and the accuracy change over time\n",
        "plot_logs(train_logs)"
      ],
      "outputs": [],
      "metadata": {
        "id": "8fWj4VfYzked"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference test"
      ],
      "metadata": {
        "id": "gbeZLfT1G_z0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Load a vocabulary\n",
        "vocab = load_vocab(path = '<PATH_TO_VOCABULARY>')\n",
        "\n",
        "# Load model weights for instance for the LSTM model\n",
        "model_params = torch.load('<PATH_TO_MODEL_WEIGHTS>', map_location=device)\n",
        "lstm.load_state_dict(model_params['model_state_dict'])\n",
        "lstm.eval()\n",
        "\n",
        "# Initialize the averagers and evaluate the model on the dev/test split\n",
        "dev_loss_avg = make_averager(precision=4)\n",
        "dev_accuracy_avg = make_averager(precision=4)\n",
        "evaluate(lstm, dev_dataloader, loss_fn, dev_loss_avg, dev_accuracy_avg)\n",
        "print(f\"Loss: {dev_loss_avg()}, accuracy: {dev_accuracy_avg()}\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "l3nmu3l0IuaM"
      }
    }
  ]
}